#!/usr/bin/env python3
"""
AutoGenå·¥ä½œæµæµ‹è¯•è„šæœ¬
åŸºäºçœŸå®çš„AutoGenå›¢é˜Ÿå·¥ä½œæµæ¨¡å¼è¿›è¡Œæµ‹è¯•
"""

import asyncio
import sys
import os
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir.parent))

# å¯¼å…¥AutoGenç»„ä»¶
try:
    from autogen_agentchat.teams import RoundRobinGroupChat
    from autogen_agentchat.agents import UserProxyAgent
    from autogen_agentchat.conditions import TextMentionTermination
    from autogen_agentchat.ui import Console

    AUTOGEN_IMPORTED = True
    print("âœ… æˆåŠŸå¯¼å…¥AutoGenç»„ä»¶")
except ImportError as e:
    print(f"âŒ å¯¼å…¥AutoGenç»„ä»¶å¤±è´¥: {e}")
    AUTOGEN_IMPORTED = False

# å¯¼å…¥æ™ºèƒ½ä½“
try:
    from agents.article_research.survey_director import get_survey_director
    from agents.article_research.paper_retriever import get_paper_retriever
    from agents.article_research.paper_analyzer import get_paper_analyzer
    from agents.article_research.knowledge_synthesizer import get_knowledge_synthesizer
    from agents.article_research.visualization_specialist import get_visualization_specialist
    from agents.article_research.report_generator import get_report_generator

    AGENTS_IMPORTED = True
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰æ™ºèƒ½ä½“æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ™ºèƒ½ä½“å¤±è´¥: {e}")
    AGENTS_IMPORTED = False


class AutoGenWorkflowTester:
    """AutoGenå·¥ä½œæµæµ‹è¯•å™¨"""

    def __init__(self):
        self.test_results = {}
        self.output_dir = Path("test_outputs")
        self.output_dir.mkdir(exist_ok=True)

    async def test_single_agent(self, agent_name: str, agent_factory, test_task: str):
        """æµ‹è¯•å•ä¸ªæ™ºèƒ½ä½“"""
        print(f"\nğŸ§ª æµ‹è¯• {agent_name}...")
        print("-" * 60)

        try:
            if not AUTOGEN_IMPORTED or not AGENTS_IMPORTED:
                raise Exception("ç¼ºå°‘å¿…è¦çš„ä¾èµ–æ¨¡å—")

            print("å¼€å§‹æ™ºèƒ½ä½“åˆå§‹åŒ–...")

            # åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹
            agent = agent_factory()
            print(f"âœ… {agent_name} å®ä¾‹åˆ›å»ºæˆåŠŸ")
            print(f"   Agentåç§°: {agent.name}")
            print(f"   å·¥å…·æ•°é‡: {len(agent.tools) if hasattr(agent, 'tools') and agent.tools else 0}")

            # æ˜¾ç¤ºå·¥å…·ä¿¡æ¯
            if hasattr(agent, 'tools') and agent.tools:
                for i, tool in enumerate(agent.tools):
                    tool_name = getattr(tool, 'name', f'Tool_{i}')
                    print(f"   å·¥å…·{i + 1}: {tool_name}")

            # åˆ›å»ºè‡ªåŠ¨ç”¨æˆ·ä»£ç†ï¼ˆé¿å…äº¤äº’ï¼‰
            user_proxy = UserProxyAgent(
                "UserProxy",
                input_func=input
            )

            # åˆ›å»ºç»ˆæ­¢æ¡ä»¶
            termination_condition = TextMentionTermination("APPROVE")

            print("å›¢é˜Ÿåˆ›å»ºå®Œæˆï¼Œå¼€å§‹è¿è¡Œæµ...")

            # åˆ›å»ºå›¢é˜Ÿ
            team = RoundRobinGroupChat(
                [agent, user_proxy],
                termination_condition=termination_condition,
                max_turns=3,  # é™åˆ¶è½®æ¬¡é¿å…æ— é™å¾ªç¯
                emit_team_events=True
            )

            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()

            # å¯åŠ¨æ¶ˆæ¯æµ
            print(f"ğŸ“ å‘é€æµ‹è¯•ä»»åŠ¡: {test_task[:100]}...")
            message_stream = team.run_stream(task=test_task)

            print("æ¶ˆæ¯æµå¯åŠ¨ï¼Œç­‰å¾…æ§åˆ¶å°è¾“å‡º...")

            # ä½¿ç”¨Consoleå¤„ç†æ¶ˆæ¯æµ
            result = await Console(
                message_stream,
                no_inline_images=True,
                output_stats=True
            )

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()

            # æå–ç»“æœå†…å®¹
            result_content = str(result) if result else "No result"

            # è®°å½•æµ‹è¯•ç»“æœ
            self.test_results[agent_name] = {
                "status": "âœ… é€šè¿‡",
                "response_length": len(result_content),
                "execution_time": execution_time,
                "tools_count": len(agent.tools) if hasattr(agent, 'tools') and agent.tools else 0,
                "response_preview": result_content[:200] + "..." if len(result_content) > 200 else result_content,
                "test_time": datetime.now().isoformat()
            }

            # ä¿å­˜å®Œæ•´å“åº”
            self.save_agent_response(agent_name, test_task, result_content)

            print(f"âœ… æµ‹è¯•æˆåŠŸå®Œæˆ")
            print(f"   å“åº”é•¿åº¦: {len(result_content)} å­—ç¬¦")
            print(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            print(f"   å“åº”é¢„è§ˆ: {result_content[:100]}...")

            return True

        except Exception as e:
            self.test_results[agent_name] = {
                "status": "âŒ å¤±è´¥",
                "error": str(e),
                "test_time": datetime.now().isoformat()
            }
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_survey_director(self):
        """æµ‹è¯•è°ƒç ”æ€»ç›‘"""
        test_task = """
        è¯·ä¸ºç ”ç©¶ä¸»é¢˜"å›¾ç¥ç»ç½‘ç»œåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨"åˆ¶å®šè¯¦ç»†çš„æ–‡çŒ®è°ƒç ”ç­–ç•¥ã€‚

        è¦æ±‚åŒ…æ‹¬ï¼š
        1. åˆ†è§£ä¸º3-5ä¸ªå­ç ”ç©¶æ–¹å‘
        2. ä¸ºæ¯ä¸ªæ–¹å‘ç”Ÿæˆè‹±æ–‡æ£€ç´¢å…³é”®è¯
        3. åˆ¶å®šæ£€ç´¢ä¼˜å…ˆçº§å’Œæ—¶é—´èŒƒå›´
        4. é¢„ä¼°éœ€è¦æ£€ç´¢çš„æ–‡çŒ®æ•°é‡

        è¯·æä¾›ç»“æ„åŒ–çš„ç­–ç•¥è§„åˆ’ã€‚
        """

        return await self.test_single_agent(
            "SurveyDirector",
            get_survey_director,
            test_task
        )

    async def test_paper_retriever(self):
        """æµ‹è¯•æ–‡çŒ®æ£€ç´¢ä¸“å®¶"""
        test_task = """
        è¯·æ£€ç´¢å…³äº"Graph Neural Networks recommendation systems"çš„ç›¸å…³å­¦æœ¯è®ºæ–‡ã€‚

        æ£€ç´¢è¦æ±‚ï¼š
        1. ä½¿ç”¨arXivç­‰å­¦æœ¯æ•°æ®åº“
        2. é‡ç‚¹å…³æ³¨æœ€è¿‘3å¹´çš„é«˜è´¨é‡æ–‡çŒ®
        3. è¿”å›è®ºæ–‡çš„è¯¦ç»†å…ƒæ•°æ®
        4. æŒ‰ç›¸å…³æ€§å’Œå¼•ç”¨æ•°æ’åº

        è¯·è°ƒç”¨é€‚å½“çš„å·¥å…·è¿›è¡Œæ£€ç´¢ï¼Œå¹¶æä¾›ç»“æ„åŒ–çš„ç»“æœã€‚
        """

        return await self.test_single_agent(
            "PaperRetriever",
            get_paper_retriever,
            test_task
        )

    async def test_paper_analyzer(self):
        """æµ‹è¯•æ–‡çŒ®åˆ†æä¸“å®¶"""
        test_paper = {
            "title": "Graph Neural Networks for Recommender Systems: A Survey",
            "authors": ["Wang, X.", "He, X.", "Wang, M.", "Feng, F.", "Chua, T.S."],
            "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful technique for modeling graph-structured data in recommender systems. This survey provides a comprehensive overview of GNN-based recommendation approaches, categorizing them into spectral-based and spatial-based methods.",
            "year": 2023,
            "citation_count": 445,
            "venue": "ACM Computing Surveys"
        }

        test_task = f"""
        è¯·å¯¹ä»¥ä¸‹è®ºæ–‡è¿›è¡Œæ·±åº¦åˆ†æï¼š

        è®ºæ–‡ä¿¡æ¯ï¼š
        {json.dumps(test_paper, ensure_ascii=False, indent=2)}

        åˆ†æè¦æ±‚ï¼š
        1. æå–æ ¸å¿ƒè´¡çŒ®å’Œåˆ›æ–°ç‚¹
        2. åˆ†æä½¿ç”¨çš„æ–¹æ³•å’ŒæŠ€æœ¯
        3. è¯„ä¼°è®ºæ–‡è´¨é‡å’Œå½±å“åŠ›
        4. è¯†åˆ«ä¸å…¶ä»–å·¥ä½œçš„å…³ç³»
        5. æå–å¯å¼•ç”¨çš„å…³é”®è§‚ç‚¹

        è¯·è°ƒç”¨åˆ†æå·¥å…·æä¾›ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚
        """

        return await self.test_single_agent(
            "PaperAnalyzer",
            get_paper_analyzer,
            test_task
        )

    async def test_knowledge_synthesizer(self):
        """æµ‹è¯•çŸ¥è¯†ç»¼åˆä¸“å®¶"""
        test_analyses = [
            {
                "paper_title": "Graph Neural Networks for Recommendation",
                "analysis": "æœ¬æ–‡æå‡ºäº†åŸºäºå›¾ç¥ç»ç½‘ç»œçš„æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ ç”¨æˆ·-ç‰©å“äº¤äº’å›¾çš„è¡¨ç¤ºæ¥æå‡æ¨èæ€§èƒ½ã€‚"
            },
            {
                "paper_title": "Neural Collaborative Filtering",
                "analysis": "è¯¥ç ”ç©¶å°†æ·±åº¦å­¦ä¹ åº”ç”¨äºååŒè¿‡æ»¤ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ ç”¨æˆ·å’Œç‰©å“çš„éçº¿æ€§äº¤äº’ã€‚"
            }
        ]

        test_task = f"""
        è¯·åŸºäºä»¥ä¸‹æ–‡çŒ®åˆ†æç»“æœè¿›è¡ŒçŸ¥è¯†ç»¼åˆï¼š

        åˆ†ææ•°æ®ï¼š
        {json.dumps(test_analyses, ensure_ascii=False, indent=2)}

        ç»¼åˆè¦æ±‚ï¼š
        1. æ„å»ºè¯¥é¢†åŸŸçš„æŠ€æœ¯åˆ†ç±»ä½“ç³»
        2. è¯†åˆ«ä¸»è¦ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿
        3. æ€»ç»“å…³é”®å‘ç°å’Œå…±è¯†
        4. è¯†åˆ«äº‰è®®ç‚¹å’Œä¸åŒè§‚ç‚¹
        5. å‘ç°ç ”ç©¶ç©ºç™½å’Œæœªæ¥æ–¹å‘

        è¯·è°ƒç”¨çŸ¥è¯†ç»¼åˆå·¥å…·ç”Ÿæˆç»“æ„åŒ–ç»“æœã€‚
        """

        return await self.test_single_agent(
            "KnowledgeSynthesizer",
            get_knowledge_synthesizer,
            test_task
        )

    async def test_visualization_specialist(self):
        """æµ‹è¯•å¯è§†åŒ–ä¸“å®¶"""
        viz_data = {
            "research_topic": "å›¾ç¥ç»ç½‘ç»œæ¨èç³»ç»Ÿ",
            "timeline_data": {
                "2018": "Graph Convolutional Networks for Web-Scale Recommender Systems",
                "2019": "Neural Graph Collaborative Filtering",
                "2020": "LightGCN: Simplifying and Powering Graph Convolution Network"
            }
        }

        test_task = f"""
        è¯·åŸºäºä»¥ä¸‹æ•°æ®åˆ›å»ºäº¤äº’å¼å¯è§†åŒ–ï¼š

        æ•°æ®å†…å®¹ï¼š
        {json.dumps(viz_data, ensure_ascii=False, indent=2)}

        å¯è§†åŒ–è¦æ±‚ï¼š
        1. åˆ›å»ºç ”ç©¶å‘å±•æ—¶é—´çº¿å›¾
        2. åŒ…å«äº¤äº’å¼åŠŸèƒ½
        3. ç”Ÿæˆå®Œæ•´çš„HTMLä»£ç 

        è¯·è°ƒç”¨å¯è§†åŒ–å·¥å…·ç”Ÿæˆå¯åµŒå…¥æŠ¥å‘Šçš„HTMLå†…å®¹ã€‚
        """

        return await self.test_single_agent(
            "VisualizationSpecialist",
            get_visualization_specialist,
            test_task
        )

    async def test_report_generator(self):
        """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆä¸“å®¶"""
        test_data = {
            "research_topic": "å›¾ç¥ç»ç½‘ç»œåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨",
            "strategy": {"research_directions": ["GNNæ¶æ„", "æ¨èç®—æ³•", "æ€§èƒ½è¯„ä¼°"]},
            "retrieved_papers": [
                {"title": "Graph Neural Networks for Recommendation", "authors": ["Wang et al."]},
                {"title": "Neural Collaborative Filtering", "authors": ["He et al."]}
            ],
            "analyzed_papers": [
                {"analysis": "GNNåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨åˆ†æ..."},
                {"analysis": "ååŒè¿‡æ»¤çš„æ·±åº¦å­¦ä¹ æ–¹æ³•..."}
            ]
        }

        test_task = f"""
        è¯·åŸºäºä»¥ä¸‹ç ”ç©¶æ•°æ®ç”Ÿæˆå®Œæ•´çš„ç»¼è¿°æŠ¥å‘Šï¼š

        ç ”ç©¶æ•°æ®ï¼š
        {json.dumps(test_data, ensure_ascii=False, indent=2)}

        æŠ¥å‘Šè¦æ±‚ï¼š
        1. ç”Ÿæˆè¯¦ç»†çš„å­¦æœ¯æŠ¥å‘Š
        2. åŒ…å«å¤šä¸ªå¼•ç”¨
        3. ä½¿ç”¨HTMLæ ¼å¼
        4. åŒ…å«å†…åµŒå¼å¼•ç”¨å’Œé“¾æ¥
        5. ä¸“ä¸šçš„å­¦æœ¯å†™ä½œé£æ ¼

        è¯·è°ƒç”¨æŠ¥å‘Šç”Ÿæˆå·¥å…·åˆ›å»ºHTMLæ ¼å¼ç»¼è¿°æŠ¥å‘Šã€‚
        """

        return await self.test_single_agent(
            "ReportGenerator",
            get_report_generator,
            test_task
        )

    async def test_collaborative_workflow(self):
        """æµ‹è¯•ååŒå·¥ä½œæµ"""
        print("\nğŸ”„ æµ‹è¯•æ™ºèƒ½ä½“ååŒå·¥ä½œæµ...")
        print("=" * 80)

        try:
            if not AUTOGEN_IMPORTED or not AGENTS_IMPORTED:
                raise Exception("ç¼ºå°‘å¿…è¦çš„ä¾èµ–æ¨¡å—")

            research_topic = "Transformeræ¶æ„åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„åº”ç”¨"
            print(f"ğŸ¯ ç ”ç©¶ä¸»é¢˜: {research_topic}")

            print("å¼€å§‹å·¥ä½œæµåˆå§‹åŒ–...")

            # åˆ›å»ºæ‰€æœ‰æ™ºèƒ½ä½“
            survey_director = get_survey_director()
            paper_retriever = get_paper_retriever()
            paper_analyzer = get_paper_analyzer()
            knowledge_synthesizer = get_knowledge_synthesizer()
            report_generator = get_report_generator()

            print("ä»£ç†åˆå§‹åŒ–å®Œæˆ")

            # åˆ›å»ºç»ˆæ­¢æ¡ä»¶
            termination_condition = TextMentionTermination("APPROVE")

            print("å›¢é˜Ÿåˆ›å»ºå®Œæˆï¼Œå¼€å§‹è¿è¡Œæµ...")

            user_proxy = UserProxyAgent(
                "UserProxy",
                input_func=input
            )

            # åˆ›å»ºå›¢é˜Ÿï¼ˆåŒ…å«æ‰€æœ‰æ™ºèƒ½ä½“ï¼‰
            team = RoundRobinGroupChat(
                [survey_director, paper_retriever, paper_analyzer, knowledge_synthesizer, report_generator,
                 user_proxy],
                termination_condition=termination_condition,
                max_turns=10,  # é™åˆ¶æœ€å¤§è½®æ¬¡
                emit_team_events=True
            )

            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()

            # æ„å»ºååŒä»»åŠ¡
            collaborative_task = f"""
            è¯·å„ä½æ™ºèƒ½ä½“ååŒå®Œæˆå…³äº"{research_topic}"çš„æ–‡çŒ®è°ƒç ”å·¥ä½œæµï¼š

            1. SurveyDirector: åˆ¶å®šè°ƒç ”ç­–ç•¥å’Œå…³é”®è¯
            2. PaperRetriever: æ ¹æ®ç­–ç•¥æ£€ç´¢ç›¸å…³æ–‡çŒ®
            3. PaperAnalyzer: åˆ†ææ£€ç´¢åˆ°çš„é‡è¦æ–‡çŒ®
            4. KnowledgeSynthesizer: ç»¼åˆåˆ†æç»“æœæ„å»ºçŸ¥è¯†ä½“ç³»
            5. ReportGenerator: ç”Ÿæˆæœ€ç»ˆçš„ç»¼è¿°æŠ¥å‘Š

            è¯·æŒ‰é¡ºåºåä½œå®Œæˆï¼Œæ¯ä¸ªæ™ºèƒ½ä½“å®Œæˆè‡ªå·±çš„ä»»åŠ¡åä¼ é€’ç»™ä¸‹ä¸€ä¸ªã€‚
            æœ€åè¯´"å·¥ä½œæµå®Œæˆ"ä»¥ç»“æŸæµç¨‹ã€‚
            """

            # å¯åŠ¨ååŒå·¥ä½œæµ
            print("å¯åŠ¨ååŒæ¶ˆæ¯æµ...")
            message_stream = team.run_stream(task=collaborative_task)

            print("æ¶ˆæ¯æµå¯åŠ¨ï¼Œç­‰å¾…ååŒå·¥ä½œå®Œæˆ...")

            # å¤„ç†æ¶ˆæ¯æµ
            result = await Console(
                message_stream,
                no_inline_images=True,
                output_stats=True
            )

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()

            # ä¿å­˜ååŒå·¥ä½œæµç»“æœ
            workflow_result = {
                "success": True,
                "research_topic": research_topic,
                "execution_time": execution_time,
                "result_content": str(result) if result else "No result",
                "agents_involved": ["SurveyDirector", "PaperRetriever", "PaperAnalyzer", "KnowledgeSynthesizer",
                                    "ReportGenerator"],
                "completion_time": datetime.now().isoformat()
            }

            # ä¿å­˜ç»“æœ
            self.save_workflow_result(workflow_result)

            print(f"âœ… ååŒå·¥ä½œæµæµ‹è¯•æˆåŠŸå®Œæˆ")
            print(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
            print(f"   æ¶‰åŠæ™ºèƒ½ä½“: {len(workflow_result['agents_involved'])} ä¸ª")

            return True

        except Exception as e:
            print(f"âŒ ååŒå·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            return False

    def save_agent_response(self, agent_name: str, task: str, response: str):
        """ä¿å­˜agentå“åº”åˆ°æ–‡ä»¶"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{agent_name}_response_{timestamp}.txt"
            filepath = self.output_dir / filename

            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"Agent: {agent_name}\n")
                f.write(f"Task: {task[:200]}...\n")
                f.write(f"Timestamp: {datetime.now().isoformat()}\n")
                f.write(f"Response Length: {len(response)} characters\n")
                f.write("-" * 80 + "\n")
                f.write(response)

            print(f"   ğŸ“„ å“åº”å·²ä¿å­˜: {filepath.name}")

        except Exception as e:
            print(f"   âŒ ä¿å­˜å“åº”å¤±è´¥: {e}")

    def save_workflow_result(self, result: dict):
        """ä¿å­˜å·¥ä½œæµç»“æœ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"collaborative_workflow_result_{timestamp}.json"
            filepath = self.output_dir / filename

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            print(f"   ğŸ“„ å·¥ä½œæµç»“æœå·²ä¿å­˜: {filepath.name}")

        except Exception as e:
            print(f"   âŒ ä¿å­˜å·¥ä½œæµç»“æœå¤±è´¥: {e}")

    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹AutoGenå·¥ä½œæµå…¨é¢æµ‹è¯•...")
        print("=" * 100)

        # æ£€æŸ¥ä¾èµ–
        if not AUTOGEN_IMPORTED:
            print("âŒ AutoGenç»„ä»¶æœªæ­£ç¡®å¯¼å…¥ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
            return False

        if not AGENTS_IMPORTED:
            print("âŒ æ™ºèƒ½ä½“æ¨¡å—æœªæ­£ç¡®å¯¼å…¥ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
            return False

        # å•ä¸ªæ™ºèƒ½ä½“æµ‹è¯•
        test_methods = [
            ("SurveyDirector", self.test_survey_director),
            ("PaperRetriever", self.test_paper_retriever),
            ("PaperAnalyzer", self.test_paper_analyzer),
            ("KnowledgeSynthesizer", self.test_knowledge_synthesizer),
            ("VisualizationSpecialist", self.test_visualization_specialist),
            ("ReportGenerator", self.test_report_generator)
        ]

        success_count = 0
        total_count = len(test_methods)

        # é€ä¸ªæµ‹è¯•æ™ºèƒ½ä½“
        for agent_name, test_method in test_methods:
            try:
                success = await test_method()
                if success:
                    success_count += 1
            except Exception as e:
                print(f"   âŒ {agent_name} æµ‹è¯•æ‰§è¡Œå‡ºé”™: {e}")
                self.test_results[agent_name] = {
                    "status": "âŒ æ‰§è¡Œé”™è¯¯",
                    "error": str(e),
                    "test_time": datetime.now().isoformat()
                }

        # ååŒå·¥ä½œæµæµ‹è¯•
        workflow_success = await self.test_collaborative_workflow()

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        self.print_test_summary(success_count, total_count, workflow_success)

        return success_count == total_count and workflow_success

    def print_test_summary(self, success_count: int, total_count: int, workflow_success: bool):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 100)
        print("ğŸ“Š AutoGenå·¥ä½œæµæµ‹è¯•æ€»ç»“")
        print("=" * 100)

        for agent_name, result in self.test_results.items():
            status = result["status"]
            print(f"{status} {agent_name}")

            if "âœ…" in status:
                print(f"     ğŸ“ å“åº”é•¿åº¦: {result.get('response_length', 0):,} å­—ç¬¦")
                print(f"     â±ï¸  æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f} ç§’")
                print(f"     ğŸ”§ å·¥å…·æ•°é‡: {result.get('tools_count', 0)}")
            else:
                if "error" in result:
                    print(f"     âŒ é”™è¯¯: {result['error']}")

            print(f"     ğŸ•’ æµ‹è¯•æ—¶é—´: {result['test_time']}")
            print()

        print(f"æ™ºèƒ½ä½“æµ‹è¯•: {success_count}/{total_count} é€šè¿‡")
        print(f"ååŒå·¥ä½œæµ: {'âœ… é€šè¿‡' if workflow_success else 'âŒ å¤±è´¥'}")
        print(f"æ•´ä½“æˆåŠŸç‡: {((success_count + (1 if workflow_success else 0)) / (total_count + 1) * 100):.1f}%")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")

        if success_count == total_count and workflow_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å‡é€šè¿‡ï¼AutoGenå·¥ä½œæµç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        elif success_count == total_count:
            print("\nâš ï¸  æ™ºèƒ½ä½“å•ç‹¬æµ‹è¯•é€šè¿‡ï¼Œä½†ååŒå·¥ä½œæµå­˜åœ¨é—®é¢˜ã€‚")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–ã€‚")


# å•ç‹¬æµ‹è¯•å‡½æ•°
async def test_individual_agent(agent_name: str):
    """æµ‹è¯•å•ä¸ªæ™ºèƒ½ä½“"""
    tester = AutoGenWorkflowTester()

    agent_tests = {
        "director": tester.test_survey_director,
        "retriever": tester.test_paper_retriever,
        "analyzer": tester.test_paper_analyzer,
        "synthesizer": tester.test_knowledge_synthesizer,
        "visualizer": tester.test_visualization_specialist,
        "generator": tester.test_report_generator
    }

    if agent_name.lower() in agent_tests:
        print(f"ğŸ§ª æµ‹è¯•å•ä¸ªæ™ºèƒ½ä½“: {agent_name}")
        success = await agent_tests[agent_name.lower()]()
        tester.print_test_summary(1 if success else 0, 1, False)
        return success
    else:
        print(f"âŒ æœªçŸ¥çš„æ™ºèƒ½ä½“åç§°: {agent_name}")
        print("å¯ç”¨çš„æ™ºèƒ½ä½“: director, retriever, analyzer, synthesizer, visualizer, generator")
        return False


async def test_workflow_only():
    """åªæµ‹è¯•ååŒå·¥ä½œæµ"""
    tester = AutoGenWorkflowTester()
    print("ğŸ”„ è¿è¡ŒååŒå·¥ä½œæµæµ‹è¯•...")
    success = await tester.test_collaborative_workflow()
    return success


# ä¸»å‡½æ•°
async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    if len(sys.argv) > 1:
        if sys.argv[1].lower() == "workflow":
            # åªæµ‹è¯•å·¥ä½œæµ
            await test_workflow_only()
        else:
            # æµ‹è¯•å•ä¸ªæ™ºèƒ½ä½“
            agent_name = sys.argv[1]
            await test_individual_agent(agent_name)
    else:
        # è¿è¡Œå…¨é¢æµ‹è¯•
        tester = AutoGenWorkflowTester()
        await tester.run_all_tests()


if __name__ == "__main__":
    print("ğŸ§ª AutoGenå·¥ä½œæµæµ‹è¯•å¯åŠ¨...")
    asyncio.run(main())